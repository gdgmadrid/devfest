{
  "999": {
    "id": 999,
    "title": "TBD",
    "description": "TBD"
  },
  "998": {
    "id": 998,
    "title": "TBD",
    "description": "TBD"
  },
  "207": {
    "id": 207,
    "title": "Closing DevFest",
    "description": "",
    "image": "/images/backgrounds/opening.jpg"
  },
  "206": {
    "id": 206,
    "title": "Coffee break",
    "description": "Coffeeeeeee!",
    "image": "/images/backgrounds/coffee-break.jpg"
  },
  "205": {
    "id": 205,
    "title": "Lunch",
    "description": "¡Comidaaaaaa!",
    "image": "/images/backgrounds/lunch.jpg"
  },
  "204": {
    "id": 204,
    "title": "Morning coffee",
    "description": "Coffeeeeeee!",
    "image": "/images/backgrounds/morning.jpg"
  },
  "203": {
    "id": 203,
    "title": "Afterparty & Networking",
    "description": "Afterparty & Networking",
    "image": "/images/backgrounds/party.jpg"
  },
  "202": {
    "id": 202,
    "title": "GDG DevFest Madrid 2016 Opening & Keynote",
    "description": "Keynote",
    "image": "/images/backgrounds/opening.jpg"
  },
  "201": {
    "id": 201,
    "title": "Registro",
    "description": "Registro",
    "image": "/images/backgrounds/registration.jpg"
  },
  "116": {
    "id": 116,
    "title": "APIs in Google Cloud Platform",
    "description": "Develop, deploy and manage APIs on any Google Cloud Platform backend.",
    "speakers": [
      14
    ],
    "language": "Español",
    "complexity": "Initial",
    "tags": [
      "Cloud"
    ]
  },
  "115": {
    "id": 115,
    "title": "TensorFlow for \"Scikit-learners\"",
    "description": "Tensorflow es la apuesta fuerte de Google hacia la comunidad de Data Science y Machine Learning. Fue presentado hace un año como la segunda generación de sistemas orientados al aprendizaje escalable y distribuido, surgido del proyecto Google Brain, que está centrado en la exploración de redes neuronales de gran tamaño. Realizaremos un acercamiento a su aplicación a través de sus APIs en proyectos de Machine Learning como lo haríamos con librerías tan conocidas como ScikitLearn o Theano. También hablaremos del framework, de sus bondades y aplicaciones y de como se incorpora en el ecosistema de aplicaciones de machine learning actual. ",
    "speakers": [
      13
    ],
    "language": "Español",
    "complexity": "Intermediate",
    "tags": [
      "TensorFlow", "MachineLearning"
    ]
  },
  "114": {
    "id": 114,
    "title": "Sysadmin",
    "description": "DOCKER; LINUX/UNIX; VAGRANT",
    "speakers": [
      12
    ],
    "language": "Español",
    "complexity": "Intermediate",
    "tags": [
      "docker", "sysadmin"
    ]
  },
  "113": {
    "id": 113,
    "title": "Máxima Performance",
    "description": "Nos meteremos en la sala de máquinas de nuestro barco, los navegadores, aprendiendo cómo funcionan y cuáles son las mejores técnicas para conseguir la máxima performance en nuestra web. Pasaremos de 0 a 60 FPS(*) entendiendo los procesos básicos de pintado y descubriremos en el final cuál es el enemigo número uno de la buena performance. Algunos temas que se tocarán: - ¿Qué es la buena performance? ¿Se puede medir una \"sensación\"? - ¿Cómo puedo mejorar la performance en móviles? - ¿Cómo de mucho impactan las micro-optimizaciones? - ¿Qué son los web workers? ¿Realmente ayudan? Cuando el #mobilefirst ya no es una opción y se ha convertido en ley, cuando la #performance importa.",
    "speakers": [
      11
    ],
    "language": "Español",
    "complexity": "Advanced",
    "tags": [
      "Polymer", "Web Components"
    ]
  },
  "112": {
    "id": 112,
    "title": "Big Migrations: Moving elephant herds",
    "description": "Deploying new services in cloud is easy, fast and does not require a huge initial investment (not to mention that it is COOL and everyboy does it nowadays). With the availability of tools for quick deployments and DevOps techniques, it is easier than ever to deploy your very own Hadoop cluster and begin harnessing the power of Big Data. However, what happens when your proof of concept (that has since its debut grown to a multiple terabyte monster and is ingesting several data streams in real time) needs to go into production? Does your cloud vendor provide you with enough performance? Do you need to add extra capacity to maintain the required service level? Can you do so while keeping costs below a certain threshold? You may reach a point where you want to switch cloud vendors to save some money. Have you thought about how much the transition itself will cost you? Traditional approaches to data migration may take several days or weeks given the volumes that Big Data handles. If you take into account the time that your business or service will be unavailable, coupled with the cost of the technical team that is needed to plan and execute this migration, your expected savings may decrease significantly or even disappear. What if you need to consolidate your data in one datacenter to follow corporate policy? What if you need to add data to your cluster that can't be legally stored in public cloud? You don't want to rebuild your solution from scratch and have to go through the same data load process that you already had when moving from traditional data warehousing solutions to a Hadoop cluster. In this workshop we will give you tips and best practices on how to move big volumes of data efficiently and with minimal downtime. There are different techniques available, what are their advantages and disadvantages? What steps do you need to follow? Deploying Hadoop was easy, maintaining it is a little bit more tricky and migrating this type of platform requires a thorough knowledge of Hadoop and its related ecosystem tools. A lot of factors must be taken into account to ensure a successful data migration: application activity periods, network bandwidth, Hadoop replication, cluster management tools such as Cloudera Manager, DNS, application endpoints and many other small details that we will show you during this tech talk.",
    "speakers": [
      10
    ],
    "language": "Español",
    "complexity": "Intermediate",
    "tags": [
      "Hadoop", "BigData"
    ]
  },
  "111": {
    "id": 111,
    "title": "Introducción a Angular 2",
    "description": "En esta charla se pretende dar una visión general al por qué de Angular 2 y cuáles son sus beneficios y sus principales conceptos estableciendo diferencias con AngularJS",
    "speakers": [
      9
    ],
    "language": "Español",
    "complexity": "Initial",
    "tags": [
      "Angular"
    ]
  },
  "110": {
    "id": 110,
    "title": "Desarrolla tu primera aplicación con iBeacon, Firebase & iOS",
    "description": "¿Eres desarrollador móvil pero desconoces la tecnología iBeacon o Firebase? Este es tu taller! Aprenderás a desarrollar una aplicación iOS capaz de detectar beacons y actualizar en tiempo real una base de datos con Firebase. ",
    "speakers": [
      1
    ],
    "language": "Español",
    "complexity": "Initial",
    "tags": [
      "Firebase", "iBeacon"
    ]
  },
  "109": {
    "id": 109,
    "title": "De 0 a 100 con Ibeacon en IOS usando firebase",
    "description": "Veremos que son eso de los iBeacons de Apple y sabremos como poder conjugarlos con una de las tecnologías que más promoción está dando Google en los últimos tiempos, Firebase. ¿Apple y Google en una misma charla para desarrollar con tecnologías de ambos mundos?",
    "speakers": [
      1
    ],
    "language": "Español",
    "complexity": "Initial",
    "tags": [
      "Firebase", "iBeacon"
    ]
  },
  "108": {
    "id": 108,
    "title": "Taller de Angular 2: de cero a producción",
    "description": "En el taller pretendo mostrar como pasar de una historia de usuario a una aplicación en producción partiendo del código que por defecto te ofrece la herramienta angular-cli. Para ello se va implementar cada uno de los conceptos de Angular 2 como: componentes, servicios, pipes, inyección de dependencias, routing, http, ... y con especial atención en la implementación de test unitarios y de aceptación. Lo ideal sería que este taller fuera después de una charla de introducción a todos estos conceptos en Angular 2, mía o de cualquier otro compañero, para poder ponerlos en acción, por eso la pongo como intermedia.",
    "speakers": [
      9
    ],
    "language": "Español",
    "complexity": "Intermediate",
    "tags": [
      "Angular", "testing"
    ]
  },
  "107": {
    "id": 107,
    "title": "Anatomía de un generador de Web Components Polymer",
    "description": "En la charla se hablará de las distintas fases de construcción de un generador de componentes. Empezando por una aproximación teórica a los Web Components, descripción rápida de la idea detrás del estándar y de las cuatro especificaciones en las que se asienta, así como de las razones por las que es necesaria una estandarización en la estructura y el proceso de generación de componentes a lo largo de uno o varios proyectos. Se hablará sobre la estructura del componente, tanto a nivel lógico, como a nivel de esquema de ficheros y carpetas. Posteriormente veremos las tareas de construcción del componente con gulp, para pre-procesar el código Sass, combinar las diferentes partes entre sí en cada construcción, etc. Diferenciaremos tanto las dependencias necesarias para el funcionamiento de la arquitectura del constructor de componentes, como las dependencias propias del componente en sí. Proseguiremos con la mecánica, concreta en el caso de los componentes, para observar los cambios en sus ficheros fuente y levantar un entorno de desarrollo local que construya continuamente nuestro componente para permitirnos disponer siempre de la última versión actualizada y recargada en nuestro navegador. Finalmente, terminaremos la charla indicando como agregar este constructor de componente al polymer cli, mediante la generación de una plantilla, usando yeoman y su enlazado, obteniendo de esta forma un generador de Web Components con polymer interactivo.",
    "speakers": [
      8
    ],
    "language": "Español",
    "complexity": "Intermediate",
    "tags": [
      "Polymer", "Web"
    ]
  },
  "106": {
    "id": 106,
    "title": "Añade tu generador de componentes al Polymer CLI",
    "description": "En Sngular estamos en proceso de desarrollo de nuestro propio CLI con el objetivo de que nuestras aplicaciones y componentes tengan el mismo scafolding y lo generemos desde la propia terminal. En este workshop queremos enseñaros como hicimos nuestro generador de componentes para que veáis que de forma sencilla podemos acceder a un generador de componentes customizado desde el comando polymer init. Para esto necesitareis traer instalado en vuestros equipos: - npm(también podreis porbar con yarn) - Polymer CLI",
    "speakers": [
      7
    ],
    "language": "Español",
    "complexity": "Initial",
    "tags": [
      "Polymer", "Web"
    ]
  },
  "105": {
    "id": 105,
    "title": "Breve introducción a Serverless y Cloud Functions",
    "description": "Haremos una revisión de la historia y los orígenes de la filosofía Serverless, así como de los conceptos claves, patrones de diseño, diferencias con un backend tradicional, ventajas e inconvenientes, estado del arte y ejemplos.",
    "speakers": [
      6
    ],
    "language": "Español",
    "complexity": "Intermediate",
    "tags": [
      "Cloud", "Serverless", "AWS", "Google", "Azure", "Containers"
    ]
  },
  "104": {
    "id": 104,
    "title": "CodeLab TensorFlow Wide+Deep",
    "description": "This CodeLab approaches Machine Learning through the Wide+Deep neural net architecture, with a running example. The different steps in modelling its architecture and hyperparameters will be exposed, and assistants will build a network to predict results on a dataset. For maximum enjoyment, a laptop with TensorFlow already installed is recommended, so that we don't use up time in installing the toolset.",
    "speakers": [
      2, 5
    ],
    "language": "Español",
    "complexity": "Intermediate",
    "tags": [
      "TensorFlow", "Machine Learning", "Neural Nets"
    ]
  },
  "103": {
    "id": 103,
    "title": "Hadoop Security: Kerberos Time",
    "description": "Introducción básica a la seguridad en Hadoop: autenticación, autorización, cifrado, etc .. . Hablaremos de kerberos y lo utilizaremos ;-)",
    "speakers": [
      3
    ],
    "language": "Español",
    "complexity": "Intermediate",
    "tags": [
      "Hadoop", "kerberos", "BigData"
    ]
  },
  "102": {
    "id": 102,
    "title": "Tensorflow : Architecture and deep dive into wide+deep neural nets design ",
    "description": "The talk drives into Tensorflow main architecture and focuses into wide+deep learning use case for recommendation engines.",
    "speakers": [
      2
    ],
    "language": "Español",
    "complexity": "Intermediate",
    "tags": [
      "TensorFlow", "Machine Learning", "Neural Nets"
    ]
  },
  "101": {
    "id": 101,
    "title": "Collaborating in ManageIQ",
    "description": "ManageIQ is an open source project to manage containers, virtual machines, networks, and storage from a single platform. Learn the key features of the product and learn how to improve it contributing for one of the leader projects in the world for cloud, based on ruby on rails and AngularJS.",
    "speakers": [
      4
    ],
    "language": "Español",
    "complexity": "Beginner",
    "tags": [
      "Cloud", "manageiq", "ruby", "rails", "rspec", "pull request", "patternfly", "contribute"
    ]
  }
}
